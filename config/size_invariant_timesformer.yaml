training:
  lr: 0.0001
  weight-decay: 0.0001
  bs: 64
  val_bs: 64
  optimizer: 'AdamW'
  scheduler: 'cosinelr' 
  gamma: 0.1
  step-size: 5
  augmentation: 'max' # min/max

test:
  bs: 16

model:
  image-size: 224
  patch-size: 1
  num-classes: 1
  num-patches: 49
  num-frames: 16
  max-identities: 2
  dim: 512
  depth: 9 # 9 v2 3 v3
  dim-head: 64
  channels: 2048
  heads: 8
  attn-dropout: 0.05
  ff-dropout: 0.05
  shift-tokens: False
  enable-size-emb: True
  enable-pos-emb: True
  enable-identity-attention: True
